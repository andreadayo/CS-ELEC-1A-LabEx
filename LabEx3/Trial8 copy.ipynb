{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import imghdr\n",
    "import os\n",
    "\n",
    "data_dir = \"hair_types\"\n",
    "image_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
    "\n",
    "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\n",
    "\n",
    "for filepath in Path(data_dir).rglob(\"*\"):\n",
    "    if filepath.suffix.lower() in image_extensions:\n",
    "        if filepath.exists():  # Check if the file exists before opening it\n",
    "            img_type = imghdr.what(filepath)\n",
    "            if img_type is None:\n",
    "                print(f\"{filepath} is not an image\")\n",
    "                os.remove(filepath)\n",
    "            elif img_type not in img_type_accepted_by_tf:\n",
    "                print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")\n",
    "                os.remove(filepath)\n",
    "        else:\n",
    "            print(f\"{filepath} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ADDED: test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "image_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"hair_types\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"hair_types\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size, \n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "\n",
    "# Count the number of samples per class in the training set\n",
    "for class_name in class_names:\n",
    "    num_samples = len([filename for filename in train_ds.file_paths if class_name in filename])\n",
    "    print(f\"Number of {class_name} samples in the training set: {num_samples}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Count the number of samples per class in the validation set\n",
    "for class_name in class_names:\n",
    "    num_samples = len([filename for filename in val_ds.file_paths if class_name in filename])\n",
    "    print(f\"Number of {class_name} samples in the validation set: {num_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Precision Training and Data Prefetching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ADDED: Mixed Precision Training -  speed up training without sacrificing much in terms of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "#tf.keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ADDED: Use the prefetch transformation to overlap the preprocessing and model execution of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "#train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "#val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(np.argmax(labels[i])))\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding max pooling layers helps reduce the spatial dimensions and control overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=image_size + (3,)))  # 64, 64, 3\n",
    "model.add(layers.Rescaling(1.0 / 255))\n",
    "\n",
    "model.add(layers.Conv2D(filters=8, kernel_size=3, strides=2, padding='same', dilation_rate=1))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=3, strides=1, padding='same', dilation_rate=1))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=1, padding='valid'))\n",
    "\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', dilation_rate=1))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=1, padding='valid'))\n",
    "\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(3))\n",
    "model.add(layers.Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model_archi_08.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Stop training when validation loss does not improve\n",
    "    patience=15,           # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "custom_optimizer = Adam(learning_rate=0.005)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=custom_optimizer,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history for loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Mark the best epoch for validation loss\n",
    "best_epoch_loss = np.argmin(history.history['val_loss'])\n",
    "plt.axvline(x=best_epoch_loss, color='r', linestyle='--', label=f'Best Epoch Loss: {best_epoch_loss}')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training history for accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Mark the best epoch for validation accuracy\n",
    "best_epoch_accuracy = np.argmax(history.history['val_accuracy'])\n",
    "plt.axvline(x=best_epoch_accuracy, color='r', linestyle='--', label=f'Best Epoch Accuracy: {best_epoch_accuracy}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best epochs\n",
    "print(f'Best Epoch for Validation Loss: {best_epoch_loss}')\n",
    "print(f'Best Epoch for Validation Accuracy: {best_epoch_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and test an image of curly hair\n",
    "img_curly = keras.preprocessing.image.load_img(\n",
    "    \"hair_types/Curly_Hair/02dac897d1dec9ba8c057a11d041ada8--layered-natural-hair-natural-black-hairstyles.jpg\", target_size=image_size\n",
    ")\n",
    "img_array_curly = keras.preprocessing.image.img_to_array(img_curly)\n",
    "img_array_curly = tf.expand_dims(img_array_curly, 0)  # Create batch axis\n",
    "\n",
    "predictions_curly = model.predict(img_array_curly)\n",
    "print(\n",
    "    \"CURLY: This image is %.2f percent curly hair, %.2f percent straight hair, and %.2f percent wavy hair.\"\n",
    "    % tuple(predictions_curly[0])\n",
    ")\n",
    "\n",
    "# Load and test an image of straight hair\n",
    "img_straight = keras.preprocessing.image.load_img(\n",
    "    \"hair_types/Straight_Hair/1-short-spiky-mens-haircut.jpg\", target_size=image_size\n",
    ")\n",
    "img_array_straight = keras.preprocessing.image.img_to_array(img_straight)\n",
    "img_array_straight = tf.expand_dims(img_array_straight, 0)  # Create batch axis\n",
    "\n",
    "predictions_straight = model.predict(img_array_straight)\n",
    "print(\n",
    "    \"STRAIGHT: This image is %.2f percent curly hair, %.2f percent straight hair, and %.2f percent wavy hair.\"\n",
    "    % tuple(predictions_straight[0])\n",
    ")\n",
    "\n",
    "# Load and test an image of wavy hair\n",
    "img_wavy = keras.preprocessing.image.load_img(\n",
    "    \"hair_types/Wavy_Hair/2-Short-High-Volume-Hairstyle.jpg\", target_size=image_size\n",
    ")\n",
    "img_array_wavy = keras.preprocessing.image.img_to_array(img_wavy)\n",
    "img_array_wavy = tf.expand_dims(img_array_wavy, 0)  # Create batch axis\n",
    "\n",
    "predictions_wavy = model.predict(img_array_wavy)\n",
    "print(\n",
    "    \"WAVY: This image is %.2f percent curly hair, %.2f percent straight hair, and %.2f percent wavy hair.\"\n",
    "    % tuple(predictions_wavy[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ADDED: give you insights into how well your model generalizes to new, unseen data based on your validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC = 0.5: The model performs no better than random chance.\n",
    "\n",
    "AUC < 0.5: The model performs worse than random chance.\n",
    "\n",
    "AUC > 0.5: The model has some discriminatory power, with higher values indicating better discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy, val_precision, val_recall, val_auc = model.evaluate(val_ds)\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation Precision: {val_precision}\")\n",
    "print(f\"Validation Recall: {val_recall}\")\n",
    "print(f\"Validation AUC: {val_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Assuming val_ds is your validation dataset\n",
    "val_images = []\n",
    "val_labels = []\n",
    "\n",
    "for images, labels in val_ds.take(3):  # Take 3 batches (adjust as needed)\n",
    "    val_images.append(images)\n",
    "    val_labels.append(labels)\n",
    "\n",
    "# Concatenate the batches to get the images and labels\n",
    "val_images = tf.concat(val_images, axis=0)\n",
    "val_labels = tf.concat(val_labels, axis=0)\n",
    "\n",
    "# Test the model on the selected validation images\n",
    "predictions = model.predict(val_images)\n",
    "\n",
    "for i in range(len(val_images)):\n",
    "    print(f\"Image {i + 1}\")\n",
    "    print(f\"True Label: {val_labels[i]}\")\n",
    "    print(f\"Predictions: {predictions[i]}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
